# Default decision tree model
# Builds a decision tree from the iris dataset to predict
# species given all other columns as predictors
bank_clean.tree <- rpart(y~.,data=bank_clean.train, method="class",control =rpart.control(minsplit =1,minbucket=5, cp=0))
# Reports the model
print(bank_clean.tree)
## VISUALIZE THE MODEL
## plot the tree structure
library(rpart.plot)
rpart.plot(bank_clean.tree)
# Default decision tree model
# Builds a decision tree from the iris dataset to predict
# species given all other columns as predictors
bank_clean.tree <- rpart(y~.,data=bank_clean.train, method="class",control =rpart.control(minsplit =1,minbucket=6, cp=0))
# Reports the model
print(bank_clean.tree)
## VISUALIZE THE MODEL
## plot the tree structure
library(rpart.plot)
rpart.plot(bank_clean.tree)
text(bank_clean.tree, use.n = TRUE)
## print the tree structure
summary(bank_clean.tree)
bank_clean<-bank[columns]
str(bank_clean)
dim(bank_clean)
summary(bank_clean)
set.seed(777)#Why do you need to set seed?
train.index <- sample(1:nrow(bank_clean), 0.7*nrow(bank_clean))
bank_clean.train <- bank_clean[train.index,]
dim(bank_clean.train)
## select the 30% left as the testing data
bank_clean.test <- bank_clean[-train.index,]
dim(bank_clean.test)
# Default decision tree model
# Builds a decision tree from the iris dataset to predict
# species given all other columns as predictors
bank_clean.tree <- rpart(y~.,data=bank_clean.train, method="class",control =rpart.control(minsplit =1,minbucket=6, cp=0))
# Reports the model
print(bank_clean.tree)
## VISUALIZE THE MODEL
## plot the tree structure
library(rpart.plot)
rpart.plot(bank_clean.tree)
text(bank_clean.tree, use.n = TRUE)
bank <- read.csv("~/GitHub/Data-Analytic-ASS3/data set/bank.csv", sep=";")
View(bank)
banktest1 <- bank
banktest1 <- banktest1[, -which(names(banktest1) == "poutcome")]
# find rows with "unknown" values and remove them
banktest1 <- banktest1 %>%
filter_all(any_vars(!is.na(.) & . != "unknown"))
#change unknown to other value in job column
mode_val <- as.character(names(which.max(table(banktest1$job))))
banktest1$job <- ifelse(banktest1$job == "unknown", mode_val, banktest1$job)
print(banktest1)
View(banktest1)
#change unknown to other value in education column
mode_val <- as.character(names(which.max(table(banktest1$education))))
banktest1$education <- ifelse(banktest1$education == "unknown", mode_val, banktest1$education)
print(banktest1)
View(banktest1)
#change unknown to other value in contact column
mode_val <- as.character(names(which.max(table(banktest1$contact))))
banktest1$contact <- ifelse(banktest1$contact == "unknown", mode_val, banktest1$contact)
print(banktest1)
View(banktest1)
# check how many "unknown" values are left
banktest1 %>%
summarise_all(list(~sum(. == "unknown"))) %>%
gather(key = "variable", value = "nr_unknown") %>%
arrange(-nr_unknown)
# display the resulting data
View(banktest1)
# check how many "unknown" values are left
banktest1 %>%
summarise_all(list(~sum(. == "unknown"))) %>%
gather(key = "variable", value = "nr_unknown") %>%
arrange(-nr_unknown)
library(dplyr)
library(tidyr)
# check how many "unknown" values are left
banktest1 %>%
summarise_all(list(~sum(. == "unknown"))) %>%
gather(key = "variable", value = "nr_unknown") %>%
arrange(-nr_unknown)
library(rpart)
library(rpart.plot)
columns <- c("age","marital","education","housing", "y")
bank_clean<-banktest1[columns]
str(bank_clean)
dim(bank_clean)
summary(bank_clean)
set.seed(777)#Why do you need to set seed?
train.index <- sample(1:nrow(bank_clean), 0.7*nrow(bank_clean))
bank_clean.train <- bank_clean[train.index,]
dim(bank_clean.train)
## select the 30% left as the testing data
bank_clean.test <- bank_clean[-train.index,]
dim(bank_clean.test)
# Default decision tree model
# Builds a decision tree from the iris dataset to predict
# species given all other columns as predictors
bank_clean.tree <- rpart(y~.,data=bank_clean.train, method="class",control =rpart.control(minsplit =1,minbucket=6, cp=0))
# Reports the model
print(bank_clean.tree)
## VISUALIZE THE MODEL
## plot the tree structure
library(rpart.plot)
rpart.plot(bank_clean.tree)
text(bank_clean.tree, use.n = TRUE)
## print the tree structure
summary(bank_clean.tree)
## make prediction using decision model
bank_clean.predictions <- predict(bank_clean.tree, bank_clean.test, type = "class")
head(bank_clean.predictions)
## Comparison table
bank_clean.comparison <- bank_clean.test
bank_clean.comparison$Predictions <- bank_clean.predictions
bank_clean.comparison[ , c("y", "Predictions")]
## View misclassified rows
disagreement.index <- bank_clean.comparison$y != bank_clean.comparison$Predictions
bank_clean.comparison[disagreement.index,]
View(iris)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
library(caret)
columns <- c("age","marital","education","housing", "y")
bank_clean<-banktest1[columns]
str(bank_clean)
dim(bank_clean)
summary(bank_clean)
bank_clean$y <- factor(bank_clean$y)
set.seed(777)#Why do you need to set seed?
train.index <- sample(1:nrow(bank_clean), 0.7*nrow(bank_clean))
bank_clean.train <- bank_clean[train.index,]
dim(bank_clean.train)
## select the 30% left as the testing data
bank_clean.test <- bank_clean[-train.index,]
dim(bank_clean.test)
# Default decision tree model
# Builds a decision tree from the banktest1 dataset to predict
# species given all other columns as predictors
bank_clean.tree <- rpart(y~.,data=bank_clean.train, method="class",control =rpart.control(minsplit =1,minbucket=6, cp=0))
# Reports the model
print(bank_clean.tree)
## VISUALIZE THE MODEL
## plot the tree structure
library(rpart.plot)
rpart.plot(bank_clean.tree)
## print the tree structure
summary(bank_clean.tree)
## MODEL EVALUATION
## make prediction using decision model
bank_clean.predictions <- predict(bank_clean.tree, bank_clean.test, type = "class")
head(bank_clean.predictions)
## Comparison table
bank_clean.comparison <- bank_clean.test
bank_clean.comparison$Predictions <- bank_clean.predictions
bank_clean.comparison[ , c("y", "Predictions")]
## View misclassified rows
disagreement.index <- bank_clean.comparison$y != bank_clean.comparison$Predictions
bank_clean.comparison[disagreement.index,]
##Confusion Matrix
confusion_matrix <- confusionMatrix(bank_clean.predictions, bank_clean.test$y)
print(confusion_matrix)
# Calculate accuracy, precision, and recall
cm <- confusionMatrix(bank_clean.predictions, bank_clean.test$y)
accuracy <- cm$overall["Accuracy"]
print(accuracy)
precision <- cm$byClass["Pos Pred Value"]
print(precision)
recall <- cm$byClass["Sensitivity"]
print(recall)
bank <- read.csv("C:/Users/jkunz/OneDrive/1. Studium/3. Semester/3. Data Analytics/Semesterprojekt LN/neues GH/Data-Analytic-ASS3/data set/bank.csv", sep=";")
View(bank)
df <- bank_clean ##load data
head(bank_clean) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first 4 coulumns of dataset because they are the predictors
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2,3,4)], nor))
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first 4 coulumns of dataset because they are the predictors
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2,3,4)], nor))
head(bank_clean) ## see the studcture
##Run nomalization on first 4 coulumns of dataset because they are the predictors
bank_norm <- as.data.frame(lapply(bank_clean[,c(1)], nor))
df <- bank_clean ##load data
head(bank_clean) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1)], nor))
summary(bank_norm)
View(bank)
View(bank)
bank_two <- df(select(age, balance))
bank_two <- df(age, balance)
bank_two <- df("age", "balance")
df <- bank ##load data
columns <- c("age", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2)], nor))
df <- bank ##load data
columns <- c("age", "duration")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2)], nor))
columns <- c("age", "duration", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2,3)], nor))
View(bank_two)
View(bank_two)
columns <- c("age", "duration")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_clean), 0.9 * nrow(bank_clean))
View(bank_two)
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2)], nor))
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1)], nor))
summary(bank_norm)
columns <- c("age", "duration")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1)], nor))
summary(bank_norm)
df <- bank ##load data
columns <- c("age", "duration", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2,3)], nor))
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2)], nor))
columns <- c("age", "duration")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_clean[,c(1,2)], nor))
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_two[,c(1,2)], nor))
df <- bank ##load data
columns <- c("age", "duration", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first coulumn of dataset because it is the predictor
bank_norm <- as.data.frame(lapply(bank_two[,c(1,2,3)], nor))
summary(bank_norm)
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
library(caret)
columns <- c("age","marital","education","housing", "y")
bank_clean<-banktest1[columns]
str(bank_clean)
dim(bank_clean)
summary(bank_clean)
bank_clean$y <- factor(bank_clean$y)
set.seed(777)#Why do you need to set seed?
train.index <- sample(1:nrow(bank_clean), 0.7*nrow(bank_clean))
bank_clean.train <- bank_clean[train.index,]
dim(bank_clean.train)
## select the 30% left as the testing data
bank_clean.test <- bank_clean[-train.index,]
dim(bank_clean.test)
# Default decision tree model
# Builds a decision tree from the banktest1 dataset to predict
# species given all other columns as predictors
bank_clean.tree <- rpart(y~.,data=bank_clean.train, method="class",control =rpart.control(minsplit =1,minbucket=6, cp=0))
# Reports the model
print(bank_clean.tree)
## VISUALIZE THE MODEL
## plot the tree structure
library(rpart.plot)
rpart.plot(bank_clean.tree)
## print the tree structure
summary(bank_clean.tree)
## MODEL EVALUATION
## make prediction using decision model
bank_clean.predictions <- predict(bank_clean.tree, bank_clean.test, type = "class")
head(bank_clean.predictions)
## Comparison table
bank_clean.comparison <- bank_clean.test
bank_clean.comparison$Predictions <- bank_clean.predictions
bank_clean.comparison[ , c("y", "Predictions")]
## View misclassified rows
disagreement.index <- bank_clean.comparison$y != bank_clean.comparison$Predictions
bank_clean.comparison[disagreement.index,]
##Confusion Matrix
confusion_matrix <- confusionMatrix(bank_clean.predictions, bank_clean.test$y)
print(confusion_matrix)
# Calculate accuracy, precision, and recall
cm <- confusionMatrix(bank_clean.predictions, bank_clean.test$y)
accuracy <- cm$overall["Accuracy"]
print(accuracy)
precision <- cm$byClass["Pos Pred Value"]
print(precision)
recall <- cm$byClass["Sensitivity"]
print(recall)
df <- bank ##load data
columns <- c("age", "duration", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first three coulumns of dataset because they are the predictor
bank_norm <- as.data.frame(lapply(bank_two[,c(1,2,3)], nor))
summary(bank_norm)
summary(bank_norm)
##extract training set
bank_train <- bank_norm[ran,]
##extract testing set
bank_test <- iris_norm[-ran,]
##extract testing set
bank_test <- bank_norm[-ran,]
##extract 1 column of train dataset because it will be used as 'cl' argument in knn function.
bank_target_category <- bank_two[ran,1]
##extract 1 column if test dataset to measure the accuracy
bank_test_category <- bank_two[-ran,1]
##load the package class
library(class)
##run knn function
pr <- knn(bank_train,bank_test,cl=bank_target_category,k=13)
##create confusion matrix
tab <- table(pr,bank_test_category)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
print("Accuracy")
accuracy(tab)
accuracy <- tab$overall["Accuracy"]
View(cm)
View(cm)
tab <- confusionMatrix(pr, bank_test_category)
print(tab)
precision <- function(x) {
# Calculate precision
TP <- diag(x)
FP <- colSums(x) - TP
precision <- TP / (TP + FP)
return(precision)
}
precision(tab)
print(tab)
##create confusion matrix
tab <- table(pr,bank_test_category)
print(tab)
tab2 <- df(tab)
tab2 <- as.data.frame(tab)
View(tab2)
View(tab2)
print(tab)
View(tab2)
##create confusion matrix
tab <- table(pr,bank_test_category)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
accuracy <- confusionMatrix(tab)$overall["Accuracy"]
accuracy <- confusionMatrix(tab)$overall["Accuracy"]
print("Accuracy")
accuracy(tab)
confusion_matrix <- table(bank_test_category, pr)
accuracy <- confusionMatrix(confusion_matrix)$overall["Accuracy"]
accuracy <- confusionMatrix(confusion_matrix)["Accuracy"]
accuracy <- confusionMatrix(confusion_matrix)$overall
accuracy <- confusionMatrix(confusion_matrix)
confusion_matrix <- table(bank_test_category, pr)
accuracy <- confusionMatrix(confusion_matrix)
library(caret)
confusion_matrix <- table(bank_test_category, pr)
accuracy <- confusionMatrix(confusion_matrix)
accuracy <- confusionMatrix(tab)$overall["Accuracy"]
##create confusion matrix
tab <- table(pr,bank_test_category)
accuracy <- confusionMatrix(tab)$overall["Accuracy"]
##create confusion matrix
tab <- table(c(pr),c(bank_test_category))
accuracy <- confusionMatrix(tab)$overall["Accuracy"]
confusion_matrix <- table(c(bank_test_category), c(pr))
confusion_matrix <- as.matrix(confusion_matrix)
accuracy <- confusionMatrix(confusion_matrix)
accuracy <- caret::confusionMatrix(confusion_matrix)$overall["Accuracy"]
library(caret)
df <- bank ##load data
columns <- c("age", "duration", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first three coulumns of dataset because they are the predictor
bank_norm <- as.data.frame(lapply(bank_two[,c(1,2,3)], nor))
summary(bank_norm)
##extract training set
bank_train <- bank_norm[ran,]
##extract testing set
bank_test <- bank_norm[-ran,]
##extract 1 column of train dataset because it will be used as 'cl' argument in knn function.
bank_target_category <- bank_two[ran,1]
##extract 1 column if test dataset to measure the accuracy
bank_test_category <- bank_two[-ran,1]
##load the package class
library(class)
##run knn function
pr <- knn(bank_train,bank_test,cl=bank_target_category,k=13)
##create confusion matrix
tab <- table(c(pr),c(bank_test_category))
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
##create confusion matrix
tab <- table(pr,bank_test_category)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
library(caret)
df <- bank ##load data
columns <- c("age", "duration", "balance")
bank_two <- df[columns]
head(bank_two) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(bank_two), 0.9 * nrow(bank_two))
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first three coulumns of dataset because they are the predictor
bank_norm <- as.data.frame(lapply(bank_two[,c(1,2,3)], nor))
summary(bank_norm)
##extract training set
bank_train <- bank_norm[ran,]
##extract testing set
bank_test <- bank_norm[-ran,]
##extract 1 column of train dataset because it will be used as 'cl' argument in knn function.
bank_target_category <- bank_two[ran,1]
##extract 1 column if test dataset to measure the accuracy
bank_test_category <- bank_two[-ran,1]
##load the package class
library(class)
##run knn function
pr <- knn(bank_train,bank_test,cl=bank_target_category,k=13)
##create confusion matrix
tab <- table(pr,bank_test_category)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
## MODEL EVALUATION
## make prediction using decision model
bank_clean.predictions <- predict(bank_clean.tree, bank_clean.test, type = "class")
library(rpart)
library(rpart.plot)
library(caret)
columns <- c("age","marital","education","housing", "y")
bank_clean<-banktest1[columns]
str(bank_clean)
bank <- read.csv("C:/Users/jkunz/OneDrive/1. Studium/3. Semester/3. Data Analytics/Semesterprojekt LN/neues GH/Data-Analytic-ASS3/data set/bank.csv", sep=";")
View(bank)
library(rpart)
library(rpart.plot)
library(caret)
columns <- c("age","marital","education","housing", "y")
bank_clean<-banktest1[columns]
str(bank_clean)
